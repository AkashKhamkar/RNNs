{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "#from keras.utils.visualize_util import plot\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open(\"data/11-0.txt\",'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\",\"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "        y[i ,char2index[label_chars[i]]] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATIONS = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False, input_shape=(SEQLEN, nb_chars), unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 10s 61us/step - loss: 2.3345\n",
      "Generating from seed: like a fro\n",
      "like a frould and alice and alice and alice and alice and alice and alice and alice and alice and alice and al==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 42us/step - loss: 2.0557\n",
      "Generating from seed: igh: then \n",
      "igh: then the the her and the said the har her and the said the har her and the said the har her and the said ==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.9514\n",
      "Generating from seed: sure shes \n",
      "sure shes all the said the could the could the could the could the could the could the could the could the cou==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 40us/step - loss: 1.8690\n",
      "Generating from seed: be civil, \n",
      "be civil, and the mant the mous the was and the mant the mous the was and the mant the mous the was and the ma==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 40us/step - loss: 1.8016\n",
      "Generating from seed: it sounded\n",
      "it sounded the mare the pare would be and a mand the mad the pare would be and a mand the mad the pare would b==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.7473\n",
      "Generating from seed:  days wron\n",
      " days wrone the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mous==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 40us/step - loss: 1.7015\n",
      "Generating from seed: ground in \n",
      "ground in a cheres and the rabbit the ratter the rabbit the ratter the rabbit the ratter the rabbit the ratter==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.6634\n",
      "Generating from seed: rth in par\n",
      "rth in parse of the project gutenberg-tm eneep of the project gutenberg-tm eneep of the project gutenberg-tm e==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.6306\n",
      "Generating from seed: n she next\n",
      "n she next to the tor she thought all the tho grepeat, and the parter the parter the parter the parter the par==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 36us/step - loss: 1.6023\n",
      "Generating from seed: uch as she\n",
      "uch as she was the door a mary a lor the dormation a mary a lor the dormation a mary a lor the dormation a mar==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 35us/step - loss: 1.5767\n",
      "Generating from seed: , bill! ca\n",
      ", bill! cat the white rabbit she was to so she was to so she was to so she was to so she was to so she was to ==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 36us/step - loss: 1.5556\n",
      "Generating from seed: ncy to cat\n",
      "ncy to cat she was to the pure while the more the more the more the more the more the more the more the more t==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.5359\n",
      "Generating from seed: nt underst\n",
      "nt understenter to herself of the mouse of the mouse of the mouse of the mouse of the mouse of the mouse of th==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 36us/step - loss: 1.5187\n",
      "Generating from seed: ing-- i se\n",
      "ing-- i sever the hatter was stand of the project gutenberg lite arain the mock turtle said to herself, and th==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.5039\n",
      "Generating from seed: ow-- at th\n",
      "ow-- at the sther when she had not they were the white rabbit she was not it it was the white rabbit she was n==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4886\n",
      "Generating from seed: are you? s\n",
      "are you? she was great the white rabbit she was the project gutenberg litere the white rabbit she was the proj==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 36us/step - loss: 1.4767\n",
      "Generating from seed: f it makes\n",
      "f it makes the white realing and the words and the mored to the white realing and the words and the mored to t==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.4648\n",
      "Generating from seed: nity for c\n",
      "nity for come to the to grow all the the cours the cater off the court the found the cater off the court the f==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4540\n",
      "Generating from seed:  i cut som\n",
      " i cut some of the mock turtle said the mock turtle said the mock turtle said the mock turtle said the mock tu==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 36us/step - loss: 1.4457\n",
      "Generating from seed: , you by t\n",
      ", you by the things the mock turtle said the mock turtle said the mock turtle said the mock turtle said the mo==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4356\n",
      "Generating from seed: cided tone\n",
      "cided tone the pattered to herself the gryphon, and the mouse did any of the troush the project gutenberg-tm t==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.4271\n",
      "Generating from seed: -tm works \n",
      "-tm works the could some to herself to her head the mock turtle soup and the mock turtle soup and the mock tur==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 38us/step - loss: 1.4185\n",
      "Generating from seed: se project\n",
      "se project gutenberg-tm license the mouse dear the mouse dear the mouse dear the mouse dear the mouse dear the==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 37us/step - loss: 1.4117\n",
      "Generating from seed:  was certa\n",
      " was certainly and the could not seement, and the could not seement, and the could not seement, and the could ==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 36us/step - loss: 1.4044\n",
      "Generating from seed: e duchess,\n",
      "e duchess, and the door and must be one of the tone to the door and must be one of the tone to the door and mu\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" %(iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATIONS)\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" %(test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # MOVE FORWARD WITH TEST_CHARS + YPRED\n",
    "        test_chars  =  test_chars[1:] + ypred\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING ON RAW TEXT FILE OF ALICE IN WONDERLAND (CONATINS PUBLISHER INFO, LISCENCES , GARBAGE)\n",
    "# AT 25 NUM_ITERATIONS GETTING LOSS - 1.\n",
    "# AT 35 NUM_ITERATIONS GETTING LOSS - 1.3553\n",
    "# AT 50 NUM_ITERATIONS GETTING LOSS - 1.3074\n",
    "# AT 100 NUM_ITERATIONS GETTING LOSS - 1.2519 \n",
    "# (eg:Generating from seed:  be collec\n",
    "# be collected round on the project gutenberg-tm electronic works in a hard, and said to herself, in a could to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
